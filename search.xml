<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>First blog</title>
    <url>/2022/05/21/first-blog/</url>
    <content><![CDATA[<p>This is my first formal blog, which is mainly used to test the deployment of content in various formats.</p>
<p>这是我的第一篇正式博客，主要用来测试各种格式的内容能否正确部署。</p>
<span id="more"></span>

<h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p><img src="/2022/05/21/first-blog/567_6.jpg" alt="567"></p>
<p><img src="/2022/05/21/first-blog/13_3-16534500390181.jpg" alt="梅花十三"></p>
<p><img src="/2022/05/21/first-blog/mona-loading-default-16534500425902.gif" alt="动图"></p>
<p>图片居中</p>
<div align="center">
    <img src="/2022/05/21/first-blog/mona-loading-default-16534500425902.gif">
</div>

<h2 id="Mathjax公式"><a href="#Mathjax公式" class="headerlink" title="Mathjax公式"></a>Mathjax公式</h2><ul>
<li><p>行内公式：\(F&#x3D;\frac{GMm}{r^2}\)</p>
</li>
<li><p>跨行公式：</p>
<p>$$F&#x3D;\frac{GMm}{r^2}$$</p>
</li>
<li><p>复杂的跨行公式：</p>
<p>$$\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx \sum_{1}^{2}\int_{0}^{1}f(x)dx$$</p>
</li>
<li><p>化学方程式：</p>
<p>$$\ce{CH2&#x3D;CH2 + Cl2 → CH2Cl-CH2Cl}$$</p>
</li>
</ul>
<h2 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h2><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> namespae std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;hello world!&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Note-tag"><a href="#Note-tag" class="headerlink" title="Note tag"></a>Note tag</h2><div class="note default">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>



<div class="note info">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>



<div class="note primary">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>



<div class="note success">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>



<div class="note warning">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>



<div class="note danger">
            <h3 id="hello-world"><a href="#hello-world" class="headerlink" title="hello world!"></a>hello world!</h3><p>hello guys!</p>
          </div>


<h2 id="Label-tag"><a href="#Label-tag" class="headerlink" title="Label tag"></a>Label tag</h2><span class="label default">桃花</span><span class="label primary">灼灼</span>，<span class="label default">宜室</span><span class="label success">宜家</span>。
<span class="label info">瓜瓞</span><span class="label danger">绵绵</span>，<span class="label warning">尔昌</span><mark>尔炽</mark>。


<h2 id="Button-tag"><a href="#Button-tag" class="headerlink" title="Button tag"></a>Button tag</h2><ul>
<li><p>Button 1：</p>
<a class="btn" href="https://zhexuetongnian.github.io/" title="title">my_blog</a>

</li>
<li><p>Button 2：</p>
<a class="btn" href="https://zhexuetongnian.github.io/"><i class="fa fa-hand-o-right"></i>my_blog</a>

</li>
<li><p>Button 3：</p>
<a class="btn" href="https://zhexuetongnian.github.io/"><i class="fa fa-hand-o-right fa-fw"></i>my_blog</a></li>
</ul>
<h2 id="Center-quote-tag"><a href="#Center-quote-tag" class="headerlink" title="Center-quote tag"></a>Center-quote tag</h2><blockquote class="blockquote-center"><p>幽僻处可有人行，点苍苔白露泠泠。<br><strong>——王实甫</strong></p>
</blockquote>


<h2 id="Video-tag"><a href="#Video-tag" class="headerlink" title="Video tag"></a>Video tag</h2><video src="dog.mp4" preload="metadata" controls playsinline poster>Sorry, your browser does not support the video tag.</video>

]]></content>
      <categories>
        <category>theme</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/05/03/hello-world/</url>
    <content><![CDATA[<p>Hello, guys! </p>
<p>This is my first post. Although I came across lots of difficulties, I eventually finished the basic frame. So I wrote this post to record this historical moment. </p>
<p>I am not trying to make this site known to many people. I just want this site to be a friend who can sincerely listen to my happiness and complaints.</p>
<p>Thus, this is a fresh start and I will sting to update my blog. If you are coincidently interested in my content, welcome to <span class="label primary">follow</span>, <span class="label success">comment</span> and <span class="label danger">share</span>!</p>
]]></content>
  </entry>
  <entry>
    <title>New semester</title>
    <url>/2024/02/20/semester/</url>
    <content><![CDATA[<div class="note danger">
            <h3 id="New-semester"><a href="#New-semester" class="headerlink" title="New semester"></a>New semester</h3>
          </div>

<p>New semester again. It has been a long time since the last blog. It was all because I’m extremely lazy instead of any other reasons. <img src="/2024/02/20/semester/image-20240220130327168.png" alt="image-20240220130327168"><img src="/2024/02/20/semester/image-20240220130419522.png" alt="image-20240220130419522"></p>
<p>Although I have made countless resolutions to change, there still haven’t appeared any symbol of improvement. But this cannot hinder me from making up my mind again.<img src="/2024/02/20/semester/image-20240220131435825.png" alt="image-20240220131435825"><img src="/2024/02/20/semester/image-20240220131504195.png" alt="image-20240220131504195"></p>
<p>So I must abandon the bad habit of laziness in the new semester. And I will update my blog as much and quickly as possible.<img src="/2024/02/20/semester/image-20240220132416701.png" alt="image-20240220132416701"></p>
<p>Welcome all of you to supervise me.</p>
]]></content>
      <categories>
        <category>Idle thoughts</category>
      </categories>
  </entry>
  <entry>
    <title>FTP-Aeolus</title>
    <url>/2024/07/31/FTP-Aeolus/</url>
    <content><![CDATA[<h1 id="一-Aeolus卫星概况"><a href="#一-Aeolus卫星概况" class="headerlink" title="一. Aeolus卫星概况"></a>一. Aeolus卫星概况</h1><p>Aeolus卫星作为第一颗观测全球范围风廓线的多普勒激光雷达卫星，于2018年8月22日发射升空。其以7天的重复周期运行在约320km的太阳同步轨道上。ESA目前已发布了由其原始数据生产的多种产品：Level-1B初始产品、Level-2A气溶胶&#x2F;云光学产品、Level-2B科学风产品和Level-2C同化风产品等（<a href="https://aeolus-ds.eo.esa.int/oads/access/%EF%BC%89%E3%80%82">https://aeolus-ds.eo.esa.int/oads/access/）。</a></p>
<p>Aeolus卫星提供的全球风廓线数据可广泛应用于数值天气预报、理解大气污染传播机理、极端天气预测等领域。</p>
<span id="more"></span>

<h1 id="二-Aeolus卫星数据下载"><a href="#二-Aeolus卫星数据下载" class="headerlink" title="二. Aeolus卫星数据下载"></a>二. Aeolus卫星数据下载</h1><ol>
<li><p><strong>注册ESA账号</strong><br>登录ESA官网（<a href="https://aeolus-ds.eo.esa.int/oads/access/login%EF%BC%89%EF%BC%8C%E6%B3%A8%E5%86%8C%E4%B8%80%E4%B8%AAESA%E8%B4%A6%E5%8F%B7">https://aeolus-ds.eo.esa.int/oads/access/login），注册一个ESA账号</a><br><img src="/2024/07/31/FTP-Aeolus/1493b9266e8c6135e7eb2caaf9391a85.png" alt="1493b9266e8c6135e7eb2caaf9391a85"></p>
</li>
<li><p><strong>下载FileZilla</strong><br>上FileZilla官网(<a href="https://www.filezilla.cn/)%E5%8D%B3%E5%8F%AF%E5%85%8D%E8%B4%B9%E4%B8%8B%E8%BD%BD">https://www.filezilla.cn/)即可免费下载</a></p>
</li>
<li><p><strong>Aeolus数据下载</strong><br>打开FileZilla，输入主机、用户名、密码等，然后点击连接，右侧（图中的4区域）就会出现Aeolus服务器上的数据文件夹。</p>
</li>
</ol>
<ul>
<li><p>主机：<code>aeolus-ds.eo.esa.int</code></p>
</li>
<li><p>用户名、密码：输入第一步注册的用户名和密码</p>
<p><img src="/2024/07/31/FTP-Aeolus/3c26f10d5ed006aca4e979e3b155dc42.png" alt="3c26f10d5ed006aca4e979e3b155dc42"></p>
</li>
</ul>
<p>​	点进ADDF文件夹，就会出现Aeolus的多种产品。</p>
<p><img src="/2024/07/31/FTP-Aeolus/f53736b7ae353db1c7771eb54df44478.png" alt="f53736b7ae353db1c7771eb54df44478"></p>
<p>​	可以右键点击下载，也可以直接将文件拖拽入本地</p>
]]></content>
      <categories>
        <category>Research</category>
      </categories>
      <tags>
        <tag>Aeolus</tag>
      </tags>
  </entry>
  <entry>
    <title>python-Wyoming</title>
    <url>/2024/08/05/python-Wyoming/</url>
    <content><![CDATA[<h1 id="0-说明"><a href="#0-说明" class="headerlink" title="0 说明"></a>0 说明</h1><p>已有很多作者发布了有关下载怀俄明大学探空数据的博客，但使用python的较少。且近期发现网站上<mark>中国地区的站点都消失了</mark>。发邮件询问了一下，原来是中国提供的数据格式更改成了BURF，<mark>他们在一个新的网站上提供这些数据：<a href="http://weather.uwyo.edu/upperair/bufrraob.shtml%E3%80%82%E6%96%B0%E7%9A%84%E7%BD%91%E7%AB%99%E4%B8%8A%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E4%B8%AD%E5%9B%BD%E5%9C%B0%E5%8C%BA%E7%9A%84%E7%AB%99%E7%82%B9">http://weather.uwyo.edu/upperair/bufrraob.shtml。新的网站上可以看到中国地区的站点</a></mark>。</p>
<p>下面开始正题</p>
<span id="more"></span>

<h1 id="1-下载Siphon"><a href="#1-下载Siphon" class="headerlink" title="1 下载Siphon"></a>1 下载Siphon</h1><p>siphon是pyhton语言写的一个工具包，可以用来下载预报数据、再分析数据以及怀俄明的探空数据。我们在其基础上修改代码以适配新网站的格式。可以采用两种方式下载：</p>
<ol>
<li><p>手动下载，然后手动添加到项目文件夹中<br>siphon下载地址：<a href="https://unidata.github.io/siphon/latest/examples/upperair/Wyoming_Request.html#sphx-glr-examples-upperair-wyoming-request-py">https://unidata.github.io/siphon/latest/examples/upperair/Wyoming_Request.html#sphx-glr-examples-upperair-wyoming-request-py</a></p>
</li>
<li><p>通过Pycharm等导入第三方包来下载，此方法更加便捷，<mark>推荐使用</mark><br>具体直接搜索siphon即可下载<br><img src="/2024/08/05/python-Wyoming/a3108fe48ce1ce0c80c5919c3da9700f.png" alt="a3108fe48ce1ce0c80c5919c3da9700f"></p>
<h1 id="2-修改siphon中的数据网址"><a href="#2-修改siphon中的数据网址" class="headerlink" title="2 修改siphon中的数据网址"></a>2 修改siphon中的数据网址</h1><p>因为siphon包还未更新至新的数据网站，仍然访问的是旧网站，就会下载不到任何数据。所以需要修改其中的部分代码。</p>
</li>
</ol>
<ul>
<li><p><strong>（1）</strong> 防止访问太过频繁而被网站封禁，添加多个IP地址和代理 <mark>（可以跳过此步）</mark><br>打开siphon中的http_util.py文件，找到<code>create_session(self)</code>函数修改为以下内容：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_session</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a new HTTP session with our user-agent set.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    session : requests.Session</span></span><br><span class="line"><span class="string">        The created session</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    See Also</span></span><br><span class="line"><span class="string">    --------</span></span><br><span class="line"><span class="string">    urlopen, set_session_options</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    my_headers = [</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/537.75.14&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Win64; x64; Trident/6.0)&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Opera/9.25 (Windows NT 5.1; U; en)&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.8.0.12) Gecko/20070731 Ubuntu/dapper-security Firefox/1.5.0.12&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Lynx/2.8.5rel.1 libwww-FM/2.14 SSL-MM/1.4.1 GNUTLS/1.2.9&#x27;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (X11; Linux i686) AppleWebKit/535.7 (KHTML, like Gecko) Ubuntu/11.04 Chromium/16.0.912.77 Chrome/16.0.912.77 Safari/535.7&quot;</span>,</span><br><span class="line">        <span class="string">&quot;Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:10.0) Gecko/20100101 Firefox/10.0 &quot;</span></span><br><span class="line">        ]</span><br><span class="line">    proxy_list = [</span><br><span class="line">        <span class="string">&#x27;http://121.43.190.89:3128&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://221.224.136.211:35101&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://103.216.103.25:80&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://175.10.223.95:8060&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://121.43.190.89:3128&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;http://222.112.240.167:80&#x27;</span></span><br><span class="line">        <span class="string">&#x27;http://218.75.102.198:8000&#x27;</span></span><br><span class="line">        <span class="string">&#x27;http://23.254.161.181:80&#x27;</span></span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># print(random.choice(proxy_list))</span></span><br><span class="line"></span><br><span class="line">    ret = requests.Session()</span><br><span class="line">    ret.headers[<span class="string">&#x27;User-Agent&#x27;</span>] = random.choice(my_headers)</span><br><span class="line">    ret.proxies.update(&#123;<span class="string">&quot;http:&quot;</span>:random.choice(proxy_list)&#125;)</span><br><span class="line">    <span class="comment"># print(ret.headers[&#x27;User-Agent&#x27;])</span></span><br><span class="line">    <span class="comment"># print(ret.proxies)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> self.options.items():</span><br><span class="line">        <span class="built_in">setattr</span>(ret, k, v)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br></pre></td></tr></table></figure>

</li>
<li><p><strong>（2）</strong> 修改下载的网址<br>找到函数<code>__init__(self):</code>，将其中的super语句修改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">super</span>(WyomingUpperAir, self).__init__(<span class="string">&#x27;http://weather.uwyo.edu/cgi-bin/bufrraob.py&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>找到函数<code>_get_data_raw(self, time, site_id)</code>，将其中的path修改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path = (<span class="string">&#x27;?src=bufr&amp;datetime=&#123;time:%Y-%m-%d&#125;%20&#123;time:%H&#125;:00:00&amp;id=&#123;stid&#125;&amp;type=TEXT:LIST&#x27;</span>).<span class="built_in">format</span>(time=time, stid=site_id)</span><br><span class="line"><span class="comment">#某站点某天数据网址示例 &#x27;http://weather.uwyo.edu/cgi-bin/bufrraob.py?src=bufr&amp;datetime=2021-01-01%2012:00:00&amp;id=54511&amp;type=TEXT:LIST&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>（3）</strong> 修改数据提取代码<br>由于新网站结构格式与原网站不同，比如新网站不再有每个站点的经纬度信息等。所以我们需要修改代码以匹配新网站，从中提取出我们需要的信息。<br>找到函数<code>_get_data(self, time, site_id)</code>，将其修改为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_data</span>(<span class="params">self, time, site_id</span>):</span><br><span class="line">    <span class="string">r&quot;&quot;&quot;Download and parse upper air observations from an online archive.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    time : datetime</span></span><br><span class="line"><span class="string">        The date and time of the desired observation.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    site_id : str</span></span><br><span class="line"><span class="string">        The three letter ICAO identifier of the station for which data should be</span></span><br><span class="line"><span class="string">        downloaded.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">        :class:`pandas.DataFrame` containing the data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 天气数据爬虫文本提取</span></span><br><span class="line">    raw_data = self._get_data_raw(time, site_id)</span><br><span class="line">    soup = BeautifulSoup(raw_data, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">    tabular_data = StringIO(soup.find_all(<span class="string">&#x27;pre&#x27;</span>)[<span class="number">0</span>].contents[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(soup.find_all(<span class="string">&#x27;pre&#x27;</span>)[<span class="number">0</span>].contents[<span class="number">0</span>])</span><br><span class="line">    col_names = [<span class="string">&#x27;pressure&#x27;</span>, <span class="string">&#x27;height&#x27;</span>, <span class="string">&#x27;temperature&#x27;</span>, <span class="string">&#x27;dewpoint&#x27;</span>, <span class="string">&#x27;direction&#x27;</span>, <span class="string">&#x27;speed&#x27;</span>]</span><br><span class="line">    df = pd.read_fwf(tabular_data, skiprows=<span class="number">5</span>, sep=<span class="string">&#x27; &#x27;</span>,infer_nrows=<span class="number">1000</span> , usecols=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>, <span class="number">7</span>], names=col_names)</span><br><span class="line">    <span class="built_in">print</span>(df)</span><br><span class="line">    df[<span class="string">&#x27;u_wind&#x27;</span>], df[<span class="string">&#x27;v_wind&#x27;</span>] = get_wind_components(df[<span class="string">&#x27;speed&#x27;</span>],</span><br><span class="line">                                                     np.deg2rad(df[<span class="string">&#x27;direction&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Drop any rows with all NaN values for T, Td, winds</span></span><br><span class="line">    df = df.dropna(subset=(<span class="string">&#x27;temperature&#x27;</span>, <span class="string">&#x27;dewpoint&#x27;</span>, <span class="string">&#x27;direction&#x27;</span>, <span class="string">&#x27;speed&#x27;</span>,</span><br><span class="line">                           <span class="string">&#x27;u_wind&#x27;</span>, <span class="string">&#x27;v_wind&#x27;</span>), how=<span class="string">&#x27;all&#x27;</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add unit dictionary</span></span><br><span class="line">    df.units = &#123;<span class="string">&#x27;pressure&#x27;</span>: <span class="string">&#x27;hPa&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;height&#x27;</span>: <span class="string">&#x27;meter&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;temperature&#x27;</span>: <span class="string">&#x27;degC&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;dewpoint&#x27;</span>: <span class="string">&#x27;degC&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;direction&#x27;</span>: <span class="string">&#x27;degrees&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;speed&#x27;</span>: <span class="string">&#x27;m/s&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;u_wind&#x27;</span>: <span class="string">&#x27;m/s&#x27;</span>,</span><br><span class="line">                <span class="string">&#x27;v_wind&#x27;</span>: <span class="string">&#x27;m/s&#x27;</span>,</span><br><span class="line">                &#125;</span><br><span class="line">  <span class="keyword">return</span> df</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="3-批量下载数据"><a href="#3-批量下载数据" class="headerlink" title="3 批量下载数据"></a>3 批量下载数据</h1><p>然后通过下面的代码就可以下载俄怀明的探空数据了：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> metpy.units <span class="keyword">import</span> units</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> siphon.simplewebservice.wyoming <span class="keyword">import</span> WyomingUpperAir</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新建文件夹函数，便于分站点存储数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mkdir</span>(<span class="params">path</span>):</span><br><span class="line">    folder = os.path.exists(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> folder:  <span class="comment"># 判断是否存在文件夹如果不存在则创建为文件夹</span></span><br><span class="line">        os.makedirs(path)  <span class="comment"># makedirs 创建文件时如果路径不存在会创建这个路径</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置下载时段（这里是UTC时刻）</span></span><br><span class="line">start = datetime.datetime(<span class="number">2020</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">end = datetime.datetime(<span class="number">2020</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">datelist = []</span><br><span class="line"><span class="keyword">while</span> start&lt;=end:</span><br><span class="line">    datelist.append(start)</span><br><span class="line">    start+=datetime.timedelta(hours=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line">datelist_s=[]</span><br><span class="line"><span class="comment"># 选择下载站点（以上海宝山站为例）</span></span><br><span class="line">stationlist = [<span class="string">&#x27;57494&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可通过外部文件批量导入站点编号</span></span><br><span class="line"><span class="comment"># sta = pd.read_csv(&quot;station.csv&quot;,encoding = &#x27;gb2312&#x27;,dtype=&#123;&quot;id&quot;: str&#125;)</span></span><br><span class="line"><span class="comment"># stationlist = sta[&#x27;id&#x27;]</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">nodata=[]</span><br><span class="line">data_missing=[]</span><br><span class="line"><span class="comment"># 批量下载</span></span><br><span class="line"><span class="keyword">for</span> station <span class="keyword">in</span> stationlist:</span><br><span class="line">    datelist_s=datelist.copy()</span><br><span class="line">    <span class="keyword">for</span> date <span class="keyword">in</span> datelist_s:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            df = WyomingUpperAir.request_data(date, station)</span><br><span class="line">            mkdir(<span class="string">&#x27;D:/RS_data/&#x27;</span>+station)    </span><br><span class="line">            df.to_csv(<span class="string">&#x27;D:/RS_data/&#x27;</span>+station+<span class="string">&#x27;/&#x27;</span>+station+<span class="string">&#x27;_&#x27;</span>+date.strftime(<span class="string">&#x27;%Y%m%d%H&#x27;</span>)+<span class="string">&#x27;.csv&#x27;</span>,index=<span class="literal">False</span>)</span><br><span class="line">            <span class="built_in">print</span>(station+date.strftime(<span class="string">&#x27;%Y%m%d_%H&#x27;</span>)+<span class="string">&#x27;下载成功&#x27;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;错误类型是&#x27;</span>,e.__class__.__name__)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;错误明细是&#x27;</span>,e)</span><br><span class="line">            <span class="built_in">print</span>(station+date.strftime(<span class="string">&#x27;%Y%m%d_%H&#x27;</span>)+<span class="string">&#x27;下载失败,原因如下：&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> e.__class__.__name__==<span class="string">&quot;IndexError&quot;</span>:</span><br><span class="line">                <span class="comment">#加入无数据队列</span></span><br><span class="line">                <span class="built_in">print</span>(</span><br><span class="line">                    <span class="string">&#x27;No data available for &#123;time:%Y-%m-%d %HZ&#125; &#x27;</span></span><br><span class="line">                    <span class="string">&#x27;for station &#123;stid&#125;.&#x27;</span>.<span class="built_in">format</span>(time=date, stid=station))</span><br><span class="line">                nodata.append(station+<span class="string">&#x27;_&#x27;</span>+date.strftime(<span class="string">&#x27;%Y%m%d%H&#x27;</span>))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">elif</span> e.__class__.__name__==<span class="string">&quot;TypeError&quot;</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Error data type in web page&#x27;</span>)</span><br><span class="line">                nodata.append(station + <span class="string">&#x27;_&#x27;</span> + date.strftime(<span class="string">&#x27;%Y%m%d%H&#x27;</span>))</span><br><span class="line">            <span class="keyword">elif</span> e.__class__.__name__==<span class="string">&quot;KeyError&quot;</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;Missing data in web page&#x27;</span>)</span><br><span class="line">                data_missing.append(station + <span class="string">&#x27;_&#x27;</span> + date.strftime(<span class="string">&#x27;%Y%m%d%H&#x27;</span>))</span><br><span class="line">                <span class="comment"># 其他需要忽略下载的错误可以继续往下加</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment">#把下载失败日期加入到下载队列末端重新下载</span></span><br><span class="line">                datelist_s.append((date))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment"># 将无数据的站点及日期写入文件</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&quot;无数据提供的站点及日期：&quot;</span>)</span><br><span class="line"> <span class="built_in">print</span>(nodata)</span><br><span class="line"> f = <span class="built_in">open</span>(<span class="string">&quot;nodata_12.txt&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line"> <span class="keyword">for</span> line <span class="keyword">in</span> nodata:</span><br><span class="line">     f.write(line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"> f.close()</span><br><span class="line"> </span><br><span class="line"> <span class="comment"># 将数据列缺失的站点及日期写入文件</span></span><br><span class="line"> <span class="built_in">print</span>(<span class="string">&quot;数据列存在缺失的站点和日期：&quot;</span>)</span><br><span class="line"> <span class="built_in">print</span>(data_missing)</span><br><span class="line"> f = <span class="built_in">open</span>(<span class="string">&quot;data_missing_12.txt&quot;</span>, <span class="string">&quot;w&quot;</span>)</span><br><span class="line"> <span class="keyword">for</span> line <span class="keyword">in</span> data_missing:</span><br><span class="line">     f.write(line + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"> f.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="4-结果展示"><a href="#4-结果展示" class="headerlink" title="4 结果展示"></a>4 结果展示</h1><ul>
<li><p>各站点数据文件夹：<br><img src="/2024/08/05/python-Wyoming/bb88d02b68e06d6c961c28abde6a9673.png" alt="bb88d02b68e06d6c961c28abde6a9673"></p>
</li>
<li><p>某站点下载的数据：</p>
<p><img src="/2024/08/05/python-Wyoming/b7894f92d443c395f276053532213ebc.png" alt="b7894f92d443c395f276053532213ebc"></p>
</li>
<li><p>某站点某天探空数据展示：<br><img src="/2024/08/05/python-Wyoming/2cc4418127d420279031720457791208.png" alt="2cc4418127d420279031720457791208"></p>
</li>
</ul>
]]></content>
      <categories>
        <category>Research</category>
      </categories>
      <tags>
        <tag>sonde</tag>
      </tags>
  </entry>
</search>
